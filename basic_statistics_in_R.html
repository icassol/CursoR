<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Facundo Bocalandro &amp; Ignacio Cassol" />

<meta name="date" content="2020-05-11" />

<title>Algunas distribuciones y simulaciones en R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<div class="header">
  <img style="width: 100%;" class="center-fit" src="resources/curso-banner.png"/>
</div>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Curso R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Mod1.html">Introducción</a>
</li>
<li>
  <a href="Mod2.html">Lenguaje R</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Estadística
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Mod3.html">Basics</a>
    </li>
    <li>
      <a href="basic_statistics_in_R.html">Distribuciones</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Gráficos
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Mod4.html">Introducción</a>
    </li>
    <li>
      <a href="Mod4_Adv.html">Avanzado</a>
    </li>
  </ul>
</li>
<li>
  <a href="Mod7.html">Predicción</a>
</li>
<li>
  <a href="Mod8.html">Clustering</a>
</li>
<li>
  <a href="Mod5.html">Reportes</a>
</li>
<li>
  <a href="Mod6.html">Web</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Algunas distribuciones y simulaciones en R</h1>
<h4 class="author">Facundo Bocalandro &amp; Ignacio Cassol</h4>
<h4 class="date">2020-05-11</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#introducción"><span class="toc-section-number">1</span> Introducción</a></li>
<li><a href="#patrones-comunes-a-las-intrucciones-de-distribución-en-r"><span class="toc-section-number">2</span> Patrones comunes a las intrucciones de distribución en R</a></li>
<li><a href="#distribuciones-discretas"><span class="toc-section-number">3</span> Distribuciones Discretas</a><ul>
<li><a href="#uniforme"><span class="toc-section-number">3.1</span> Uniforme</a></li>
<li><a href="#bernoulli"><span class="toc-section-number">3.2</span> Bernoulli</a></li>
<li><a href="#binomial"><span class="toc-section-number">3.3</span> Binomial</a></li>
<li><a href="#geométrica"><span class="toc-section-number">3.4</span> Geométrica</a></li>
<li><a href="#binomial-negativa"><span class="toc-section-number">3.5</span> Binomial negativa</a></li>
<li><a href="#hipergeometrica"><span class="toc-section-number">3.6</span> Hipergeometrica</a></li>
<li><a href="#poisson"><span class="toc-section-number">3.7</span> Poisson</a></li>
</ul></li>
<li><a href="#distribuciones-continuas"><span class="toc-section-number">4</span> Distribuciones continuas</a><ul>
<li><a href="#normal"><span class="toc-section-number">4.1</span> Normal</a></li>
</ul></li>
<li><a href="#resumen-de-las-intrucciones-de-distribución-en-r"><span class="toc-section-number">5</span> Resumen de las intrucciones de distribución en R</a></li>
<li><a href="#resueltos"><span class="toc-section-number">6</span> Resueltos</a><ul>
<li><a href="#μ-σμσ"><span class="toc-section-number">6.1</span> [μ-σ;μ+σ]</a></li>
<li><a href="#función-de-densidad-esperanza-y-varianza"><span class="toc-section-number">6.2</span> función de densidad, esperanza y varianza</a></li>
<li><a href="#bolillero-de-15-bolillas"><span class="toc-section-number">6.3</span> Bolillero de 15 bolillas</a></li>
<li><a href="#varias-distribuciones-para-el-tcl"><span class="toc-section-number">6.4</span> Varias distribuciones para el TCL</a></li>
</ul></li>
<li><a href="#material-para-consulta"><span class="toc-section-number">7</span> Material para consulta</a></li>
</ul>
</div>

<!-- see http://rmarkdown.rstudio.com/ for details in formatting -->
<p>Paquete de R necesario para este hands-on:</p>
<pre class="r"><code>if (!is.element(&quot;VennDiagram&quot;, installed.packages()[,1])){
  install.packages(&quot;VennDiagram&quot;)
}
library(VennDiagram)</code></pre>
<pre><code>## Loading required package: grid</code></pre>
<pre><code>## Loading required package: futile.logger</code></pre>
<pre class="r"><code>if (!is.element(&quot;visualize&quot;, installed.packages()[,1])){
  install.packages(&quot;visualize&quot;)
}

library(visualize)
if (!is.element(&quot;stargazer&quot;, installed.packages()[,1])){
  install.packages(&quot;stargazer&quot;)
}

library(stargazer)</code></pre>
<pre><code>## 
## Please cite as:</code></pre>
<pre><code>##  Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables.</code></pre>
<pre><code>##  R package version 5.2.2. https://CRAN.R-project.org/package=stargazer</code></pre>
<div id="introducción" class="section level1">
<h1><span class="header-section-number">1</span> Introducción</h1>
<p>En este archivo encontrarán una introducción a las distribuciones estadísticas en R.</p>
<p>Los conceptos teóricos, las definiciones y las fórmulas de cada distibución ya fueron explicadas en clase. El objetivo de este hands-on es aplicar esos conceptos y fórmulas en el lenguaje R y hacer simulaciones para mostar empíricamente algunos de esos conceptos.</p>
</div>
<div id="patrones-comunes-a-las-intrucciones-de-distribución-en-r" class="section level1">
<h1><span class="header-section-number">2</span> Patrones comunes a las intrucciones de distribución en R</h1>
<p>Las funciones para distribuciones de probabilidad en R se separan en 4 grandes categorías:</p>
<ul>
<li>Prefijo r: Simular experimento aleatorio</li>
<li>Prefijo d: Funcion de densidad de probabilidad</li>
<li>Prefijo p: Funcion de distribucion acumulada</li>
<li>Prefijo q: Funcion percentil</li>
</ul>
</div>
<div id="distribuciones-discretas" class="section level1">
<h1><span class="header-section-number">3</span> Distribuciones Discretas</h1>
<div id="uniforme" class="section level2">
<h2><span class="header-section-number">3.1</span> Uniforme</h2>
<p>Vamos a guardar en un arreglo la probabilidad de que salga cada cara de un dado:</p>
<pre class="r"><code>p.de.cada.cara &lt;- rep(1/6,6)
sum(p.de.cada.cara) # check</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>ncara &lt;- 1:6

esperanza &lt;- sum(ncara*p.de.cada.cara)
esperanza</code></pre>
<pre><code>## [1] 3.5</code></pre>
<hr />
</div>
<div id="bernoulli" class="section level2">
<h2><span class="header-section-number">3.2</span> Bernoulli</h2>
<div id="simulaciones-singulares" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Simulaciones singulares</h3>
<p>Vamos a usar la función <code>sample()</code> para mostrar el resultado particular de a) tirar un dado, a) tirar una moneda equilibrada y c) tirar tres veces un dado:</p>
<pre class="r"><code># función básica para tirar un dado una vez: 
sample(1:6, 1)</code></pre>
<pre><code>## [1] 3</code></pre>
<pre class="r"><code># función básica para tirar una moneda equilibrada:
sample(c(&quot;cara&quot;, &quot;cruz&quot;), 1) </code></pre>
<pre><code>## [1] &quot;cara&quot;</code></pre>
<pre class="r"><code># función básica para tirar un dado tres veces con reposición: 
sample(1:6, 3, replace = T)</code></pre>
<pre><code>## [1] 2 5 5</code></pre>
</div>
<div id="simulaciones-múltiples" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Simulaciones múltiples</h3>
<p>Vamos a mostrar, empíricamente, que la VA X = “Resultado de lanzar un dado” es equiprobable:</p>
<pre class="r"><code># cantidad de veces que vamos a tirar el dado:
nsample&lt;-1000

# voy a tirar &quot;nsample&quot; dados:
samples&lt;-sample(ncara, size=nsample, prob=p.de.cada.cara, replace=T)

freqs&lt;-table(samples)
freqs</code></pre>
<pre><code>## samples
##   1   2   3   4   5   6 
## 165 162 156 161 172 184</code></pre>
<pre class="r"><code>lbls = sprintf(&quot;%0.1f%%&quot;, freqs/sum(freqs)*100)
barX &lt;- barplot(freqs, ylim=c(0,250))
text(x=barX, y=freqs+10, label=lbls)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/bern2-1.png" width="432" /></p>
<p>De la tabla de frecuencia y/o del barplot se observa que todas las caras de los dados tienden a salir un nro de veces similar.</p>
<hr />
<p>Ejercicio:</p>
<p>Un bolillero para un examen tiene 15 bolillas.</p>
<ol style="list-style-type: decimal">
<li><p>Suponga que el examen consiste en explicar 3 bolillas estraídas del bolillero. Simule la generación de los tres temas que le tocaría a un alumno al azar.</p></li>
<li><p>Muestre, a través de una simulación, que la probabilidad de que un alumno saque un tema es la misma para todos los temas.</p></li>
</ol>
<p>Nota: Resuelto al final del hands-on</p>
<hr />
<p>Vamos a mostrar que la esperanza de tirar un dado muchas veces es 3.5: (o sea, vamos a mostrar empíricamente el valor de la esperanza)</p>
<p>1° Tiraremos el dado 10.000 veces y vamos a calcular la media de esas 10000 veces:</p>
<pre class="r"><code>mean(sample(1:6, 10000, replace = T))</code></pre>
<pre><code>## [1] 3.5254</code></pre>
<p>2° Vamos a repetir muchas veces el experimento de tirar “n” veces un dado. A cada experimento lo vamos a llamar “muestra de la población”. Y vamos a mostrar que la media de todas las muestras sigue una distribución normal:</p>
<pre class="r"><code># La siguiente función genera la media de 1000 experimentos.
# En cada experimento tiro &quot;n&quot; veces el dado

generate.sample.means &lt;- function(n) {
  sample.means &lt;- numeric()
  for (i in 1:1000) { 
    sample.means &lt;- append(sample.means, 
            sum(sample(ncara, size=n, prob=p.de.cada.cara, replace=T))/n)
  }
  return (sample.means)
}

sample.means &lt;- generate.sample.means(100)
plot(density(sample.means), 
     main=&quot;Distribución de la media&quot;,xlab=&quot;media de los experimentos&quot;, 
     col=&quot;orange&quot;)

x = seq(3,4,0.01)

# función de densidad teórica para una media de 3.5 y un sd de 0.1707825.
mimean&lt;-mean(sample.means)
misd&lt;-sd(sample.means)

# comparamos el desvío standard teórico contra el empírico: 
sqrt(sum( (1:6-3.5)^2 ) / 6) / sqrt(100)</code></pre>
<pre><code>## [1] 0.1707825</code></pre>
<pre class="r"><code>misd  </code></pre>
<pre><code>## [1] 0.1662789</code></pre>
<pre class="r"><code>lines(x=x,y=dnorm(x,mean=mimean,sd=misd), col=rgb(0x33,0x66,0xAA,0x90,maxColorValue=255), type=&quot;l&quot;, lty=2)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/bern4-1.png" width="432" /></p>
<p>La gráfica anterior muestra las dos distribuciones: la empírica (punteada) y la teórica (continua). Lógicamente la función empírica “se aproxima” a la función teórica y no es perfecta.</p>
</div>
<div id="ley-de-los-grandes-números" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Ley de los grandes números</h3>
<p>Siguiendo la simulación anterior…</p>
<p>En la medida que agrandamos el “n” (100, en este caso) =&gt; la media empírica tiende a parecerse más a la media poblacional! A esto se le llama “ley de los grandes números”:</p>
<pre class="r"><code>sample.means &lt;- generate.sample.means(100)
plot(density(sample.means), main=&quot;Distribución de las medias de las muestras&quot;, xlab=&quot;media la muestra&quot;, col=&quot;yellow&quot;, xlim=c(3.2,3.8), ylim=c(0,8))

sample.means &lt;- generate.sample.means(500)
lines(density(sample.means), col=&quot;orange&quot;)

sample.means &lt;- generate.sample.means(1000)
lines(density(sample.means), col=&quot;red&quot;)
legend(3.6,7,c(&quot;n=100&quot;,&quot;n=500&quot;,&quot;n=1000&quot;), fill=c(&quot;yellow&quot;, &quot;orange&quot;, &quot;red&quot;))</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-1-1.png" width="432" /></p>
<hr />
</div>
</div>
<div id="binomial" class="section level2">
<h2><span class="header-section-number">3.3</span> Binomial</h2>
<p>Ejercicio 3.4 “Lanzamiento de dado”: Se lanza un dado de 6 caras (no cargado) 10 veces.</p>
<pre class="r"><code>#x: numero de exitos
exitosE &lt;- c(0,1)

#size: numero de ensayos
ensayosBinom &lt;- 10

#prob: probabilidad de exito
probabilidadBinom &lt;- 1/6</code></pre>
<p>Podemos representar fácilmente la función de probabilidad de esta distribución binomial:</p>
<pre class="r"><code>plot(dbinom(0:10,ensayosBinom,probabilidadBinom),type=&quot;h&quot;,xlab=&quot;k&quot;,ylab=&quot;P(X=k)&quot;,main=&quot;Función de Probabilidad&quot;)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-2-1.png" width="432" /></p>
<p>También podemos representar su función de distribución:</p>
<pre class="r"><code>plot(stepfun(0:10,pbinom(0:11,ensayosBinom,probabilidadBinom)),xlab=&quot;k&quot;,ylab=&quot;F(k)&quot;,main=&quot;Función de distribución&quot;)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-3-1.png" width="432" /></p>
<p>3.4.a) Calcular la probabilidad de que aparezca algún as:</p>
<p>Vamos a resolverlo de 4 maneras posibles.</p>
<pre class="r"><code>#op1: 
sum(dbinom(1:10, ensayosBinom, probabilidadBinom))</code></pre>
<pre><code>## [1] 0.8384944</code></pre>
<pre class="r"><code>#op2:
1- dbinom(0, ensayosBinom, probabilidadBinom)</code></pre>
<pre><code>## [1] 0.8384944</code></pre>
<pre class="r"><code># op3:
1 - pbinom(0, ensayosBinom, probabilidadBinom)</code></pre>
<pre><code>## [1] 0.8384944</code></pre>
<pre class="r"><code># op4:
pbinom(0, ensayosBinom, probabilidadBinom,lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.8384944</code></pre>
<p>Calcular la probabilidad de que aparezca al menos dos ases:</p>
<p>3.4.c) Calcular la probabilidad de que aparezca ningún as:</p>
<pre class="r"><code>dbinom(0, ensayosBinom, probabilidadBinom)</code></pre>
<pre><code>## [1] 0.1615056</code></pre>
<p>3.4.d) Calcular la probabilidad de que aparezca más de un as:</p>
<pre class="r"><code>sum(dbinom(2:10, ensayosBinom, probabilidadBinom))</code></pre>
<pre><code>## [1] 0.5154833</code></pre>
<p>3.4.e) Calcular la probabilidad de que aparezca menos de dos ases:</p>
<pre class="r"><code>Ej3.4.e&lt;-sum(dbinom(0:1, ensayosBinom, probabilidadBinom))</code></pre>
<p>3.4.f) Calcular la probabilidad de que aparezca a lo sumo dos ases:</p>
<p>Los vamos a resolver de dos maneras posibles.</p>
<pre class="r"><code># op1: usando la función de densidad
sum(dbinom(0:2, ensayosBinom, probabilidadBinom))</code></pre>
<pre><code>## [1] 0.7752268</code></pre>
<pre class="r"><code># op2: usando la función de distribución acumulada
#pbinom(q, size, prob, lower.tail = TRUE, log.p = FALSE)
pbinom(2, ensayosBinom, probabilidadBinom)</code></pre>
<pre><code>## [1] 0.7752268</code></pre>
<p>3.4.h) Calcular la probabilidad de que aparezca entre 2 y 4 ases (incluidos):</p>
<pre class="r"><code>pbinom(4, ensayosBinom, probabilidadBinom) - Ej3.4.e</code></pre>
<pre><code>## [1] 0.5000213</code></pre>
<hr />
<div id="link-entre-binomial-e-hipergeométrica" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Link entre binomial e hipergeométrica</h3>
<p>Se extrae una muestra de 100 personas de una población de 600,000 habitantes. Si se sabe que el 40% de la población da COVID positivo. ¿cuál es la probabilidad de que 35 o menos (personas) en la muestra den COVID positivo?</p>
<p>Los podemos resolver de dos maneras: con una binomial o con una hypergeométrica.</p>
<pre class="r"><code># op1:
pbinom(35,100,0.4)</code></pre>
<pre><code>## [1] 0.1794694</code></pre>
<p>Nota: ¿es correcto utilizar una binomial en este ejemplo? Justificar. Se puede suponer que 600,000 es lo suficientemente grande como para que las extracciones de las muestras puedan dar a entender que son independientes. RECORDAR que la binomial es con reposición.</p>
<p>Una buena alternativa es resolver el ejercicio con una hipergeométrica:</p>
<pre class="r"><code># op2:
phyper(35,240000,360000, 100)</code></pre>
<pre><code>## [1] 0.1794489</code></pre>
<p>Vamos a simular los 600.000 habitantes y hallar el valor empíricamente. Para esto, generaremos 5000 muestras de 100 personas cada una:</p>
<pre class="r"><code>population &lt;- rep(c(0,1),c(360000, 240000))
length(population)</code></pre>
<pre><code>## [1] 600000</code></pre>
<pre class="r"><code>mean(population)</code></pre>
<pre><code>## [1] 0.4</code></pre>
<pre class="r"><code>sd(population)</code></pre>
<pre><code>## [1] 0.4898984</code></pre>
<pre class="r"><code># cantidad de experimentos/muestras. Es decir: cantidad de veces que extraigo 100 personas al azar de la población.
nsamples&lt;-5000

## visualización de los vectores

sums &lt;- sapply(1:nsamples, function(x) { sum(sample(population,100))})

# la proporción del promedio de sums es similar a la proporción de la binomial

# op3: 
sum(sums &lt;= 35) / nsamples</code></pre>
<pre><code>## [1] 0.176</code></pre>
<p>Ahora vamos a mostrar que la media de todos los experimentos es la media poblacional:</p>
<pre class="r"><code>means_experiment &lt;- sapply(1:nsamples, function(x) { mean(sample(population,100))})
mean(means_experiment)</code></pre>
<pre><code>## [1] 0.40014</code></pre>
<pre class="r"><code>sd(means_experiment)</code></pre>
<pre><code>## [1] 0.04866266</code></pre>
<pre class="r"><code># vamos a comparar la función de densidad población vs la función de la media muestral: 
curve(dnorm(x, 0.4, sd(population)/sqrt(100)), 0.2, 0.6, col=&#39;blue&#39;)
lines(density(means_experiment), lty=2)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-12-1.png" width="432" /></p>
<hr />
</div>
</div>
<div id="geométrica" class="section level2">
<h2><span class="header-section-number">3.4</span> Geométrica</h2>
<p>Se lanza al aire una moneda cargada 8 veces, de tal manera que la probabilidad de que aparezca cara es de 2/3, mientras que la probabilidad de que aparezca cruz es de 1/3. Determine la probabilidad de que en el ultimo lanzamiento aparezca cara.</p>
<pre class="r"><code>#x: numero de repeticiones hasta el primer exito
repeticiones &lt;- 7

probabilidadCara &lt;- 2/3

# ajustar la p

#Resolucion
resultadoGeom &lt;- dgeom(repeticiones, probabilidadCara)</code></pre>
<p>Calcular la probabilidad de que en el experimento anterior, aparezca cara entre el tiro 5 y 8:</p>
<pre class="r"><code># op1: 
pgeom(repeticiones, probabilidadCara) - pgeom(repeticiones-4, probabilidadCara)</code></pre>
<pre><code>## [1] 0.01219326</code></pre>
<pre class="r"><code># op2:
sum(dgeom(4:7, probabilidadCara))</code></pre>
<pre><code>## [1] 0.01219326</code></pre>
<hr />
<p>Supongamos que tenemos una moneda equilibrada (probabilidad de cara=cruz=0.5). Vamos a realizar 100 experimentos en donde cada experimento es “el número de veces que tengo que tirar la moneda hasta que salga una cara”.</p>
<pre class="r"><code># Un experimento concreto sería: 
## (puede ejecutar varias veces la sig instrucción)
rgeom(1,0.5)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code># Vamos a generar los 100 experimentos: 
nsample&lt;-100

geom_samples &lt;- rgeom(nsample, 0.5)

hist(geom_samples, col=&#39;light grey&#39;, border=&#39;grey&#39;, xlab=NULL,ylab=NULL,main=NULL)
par(new=T)
plot(density(geom_samples), col=&#39;blue&#39;, axes=F)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/geom2-1.png" width="432" /></p>
<hr />
</div>
<div id="binomial-negativa" class="section level2">
<h2><span class="header-section-number">3.5</span> Binomial negativa</h2>
<p>Se sabe que la probabilidad de que un niño expuesto a una enfermedad contagiosa contraiga la enfermedad es de 0.4. Calcula la probabilidad de que el décimo niño estudiado sea el tercero en contraer la enfermedad.</p>
<pre class="r"><code>#x: numero de fallas hasta el r-esimo exito.
fallasBNeg &lt;- 7

#size: numero de exitos (r)
exitosBNeg &lt;- 3

probabilidadBNeg &lt;- 0.4

#resolucion
resultadoBNeg &lt;- dnbinom(fallasBNeg, exitosBNeg, probabilidadBNeg)</code></pre>
<hr />
<p>El 60% de una gran cantidad de bujías viejas todavía se pueden usar. Se las puede probar individualmente. Sea Y el “número de bujías que se probarán para encontrar 5 en buen estado”. ¿P[Y&lt;=10]?.</p>
<pre class="r"><code># op1:
sum(dnbinom(x=0:5,size=5,prob=0.6))</code></pre>
<pre><code>## [1] 0.8337614</code></pre>
<pre class="r"><code># op2:
pnbinom(5, size=5, prob=0.6)</code></pre>
<pre><code>## [1] 0.8337614</code></pre>
<div id="diagrama-de-venn" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Diagrama de Venn</h3>
<p>Vamos a crear 3 conjuntos de pacientes:</p>
<pre class="r"><code>diabeticos&lt;-c(&quot;Pedro&quot;, &quot;Jose&quot;, &quot;Carolina&quot;, &quot;Mariana&quot;, &quot;Antonio&quot;, &quot;Eduardo&quot;)
obesos&lt;-c(&quot;Ricardo&quot;, &quot;Jose&quot;, &quot;Carolina&quot;, &quot;Carmen&quot;, &quot;Felipe&quot;, &quot;Eduardo&quot;)
fumadores&lt;-c(&quot;Juan&quot;, &quot;Jose&quot;, &quot;Carolina&quot;, &quot;Mariana&quot;, &quot;Carmen&quot;, &quot;Bruno&quot;)

length(diabeticos)</code></pre>
<pre><code>## [1] 6</code></pre>
<pre class="r"><code>length(obesos)</code></pre>
<pre><code>## [1] 6</code></pre>
<pre class="r"><code>length(fumadores)</code></pre>
<pre><code>## [1] 6</code></pre>
<p>Ejemplo de unión de dos conjuntos:</p>
<pre class="r"><code>union(diabeticos,obesos)</code></pre>
<pre><code>## [1] &quot;Pedro&quot;    &quot;Jose&quot;     &quot;Carolina&quot; &quot;Mariana&quot;  &quot;Antonio&quot;  &quot;Eduardo&quot;  &quot;Ricardo&quot;  &quot;Carmen&quot;  
## [9] &quot;Felipe&quot;</code></pre>
<p>Ejemplo de intersección de dos conjuntos:</p>
<pre class="r"><code>intersect(diabeticos,fumadores)</code></pre>
<pre><code>## [1] &quot;Jose&quot;     &quot;Carolina&quot; &quot;Mariana&quot;</code></pre>
<p>Porcentaje de elementos comunes:</p>
<pre class="r"><code>length(intersect(diabeticos,obesos))/length(union(diabeticos,obesos))</code></pre>
<pre><code>## [1] 0.3333333</code></pre>
<p>Pacientes diabéticos que no son obesos:</p>
<pre class="r"><code>setdiff(diabeticos,obesos)</code></pre>
<pre><code>## [1] &quot;Pedro&quot;   &quot;Mariana&quot; &quot;Antonio&quot;</code></pre>
<p>Pacientes obesos que no son diabéticos:</p>
<pre class="r"><code>setdiff(obesos,diabeticos)</code></pre>
<pre><code>## [1] &quot;Ricardo&quot; &quot;Carmen&quot;  &quot;Felipe&quot;</code></pre>
<p>Dibujamos un diagrama de Venn para dos conjuntos:</p>
<pre class="r"><code>grid.newpage()
draw.pairwise.venn(length(diabeticos), 
                   length(obesos), 
                   length(intersect(diabeticos,obesos)), 
                   category = c(&quot;diabeticos&quot;, &quot;obesos&quot;), lty = rep(&quot;blank&quot;, 2), 
                   fill = c(&quot;light blue&quot;, &quot;pink&quot;), alpha = rep(0.5, 2), cat.pos = c(0, 0), 
                   cat.dist = rep(0.025, 2))</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-19-1.png" width="432" /></p>
<pre><code>## (polygon[GRID.polygon.1], polygon[GRID.polygon.2], polygon[GRID.polygon.3], polygon[GRID.polygon.4], text[GRID.text.5], text[GRID.text.6], text[GRID.text.7], text[GRID.text.8], text[GRID.text.9])</code></pre>
<p>Diagrama de Venn para tres conjuntos:</p>
<pre class="r"><code>grid.newpage()
draw.triple.venn(area1 = length(diabeticos), 
                 area2 = length(obesos), 
                 area3 = length(fumadores), 
                 n12 = length(intersect(diabeticos,obesos)), 
                 n23 = length(intersect(obesos,fumadores)), 
                 n13 = length(intersect(diabeticos,fumadores)), 
                 n123 = length(intersect(intersect(diabeticos,obesos),fumadores)), 
                 category = c(&quot;diabeticos&quot;, &quot;obsesos&quot;, &quot;fumadores&quot;), lty = &quot;blank&quot;, 
                 fill = c(&quot;skyblue&quot;, &quot;pink1&quot;, &quot;mediumorchid&quot;))</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-20-1.png" width="432" /></p>
<pre><code>## (polygon[GRID.polygon.10], polygon[GRID.polygon.11], polygon[GRID.polygon.12], polygon[GRID.polygon.13], polygon[GRID.polygon.14], polygon[GRID.polygon.15], text[GRID.text.16], text[GRID.text.17], text[GRID.text.18], text[GRID.text.19], text[GRID.text.20], text[GRID.text.21], text[GRID.text.22], text[GRID.text.23], text[GRID.text.24], text[GRID.text.25])</code></pre>
<p>Calculamos analíticamente las intersecciones de los tres conjuntos:</p>
<pre class="r"><code>experimento&lt;-list(&quot;diabeticos&quot;= diabeticos,&quot;obesos&quot;= obesos,&quot;fumadores&quot;=fumadores)

intersecciones&lt;-get.venn.partitions(experimento, keep.elements = T, force.unique = T)

View(intersecciones)</code></pre>
<p>Veamos un ejemplo con genes:</p>
<pre class="r"><code># generamos 1000 genes
gene_list = paste0(&quot;GENE&quot;, 1:1000)

# generamos tres conjuntos de 700 genes cada uno. 
studies = list( S1=sample(gene_list, 700, replace = FALSE),
                S2=sample(gene_list, 700, replace = FALSE),
                S3=sample(gene_list, 700, replace = FALSE) )

ol = calculate.overlap(x = studies)

interseccionesGenes&lt;-get.venn.partitions(studies, keep.elements = T, force.unique = T)

View(interseccionesGenes)

grid.newpage()
draw.triple.venn(area1 = length(studies$S1), 
                 area2 = length(studies$S2), 
                 area3 = length(studies$S3), 
                 n12 = length(intersect(studies$S1,studies$S2)), 
                 n23 = length(intersect(studies$S2,studies$S3)), 
                 n13 = length(intersect(studies$S1,studies$S3)), 
                 n123 = length(intersect(intersect(studies$S1,studies$S2),studies$S3)), 
                 category = c(&quot;S1&quot;, &quot;S2&quot;, &quot;S3&quot;), lty = &quot;blank&quot;, 
                 fill = c(&quot;skyblue&quot;, &quot;pink1&quot;, &quot;mediumorchid&quot;))</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/venn2-1.png" width="432" /></p>
<pre><code>## (polygon[GRID.polygon.26], polygon[GRID.polygon.27], polygon[GRID.polygon.28], polygon[GRID.polygon.29], polygon[GRID.polygon.30], polygon[GRID.polygon.31], text[GRID.text.32], text[GRID.text.33], text[GRID.text.34], text[GRID.text.35], text[GRID.text.36], text[GRID.text.37], text[GRID.text.38], text[GRID.text.39], text[GRID.text.40], text[GRID.text.41])</code></pre>
<hr />
</div>
</div>
<div id="hipergeometrica" class="section level2">
<h2><span class="header-section-number">3.6</span> Hipergeometrica</h2>
<p>De cada 20 piezas fabricadas por una máquina, hay 2 que son defectuosas. Para realizar un control de calidad, se observan 15 elementos y se rechaza el lote si hay alguna que sea defectuoso. Vamos a calcular la probabilidad de que el lote no sea rechazado.</p>
<pre class="r"><code>#x: cantidad de exitos
exitosHGeom &lt;- 0

#m: numero de exitos en la poblacion
exitosEnPoblacion &lt;- 2

#n: numero de fracasos en la poblacion
fallasHGeom &lt;- 18

#k: tamaño de la muestra extraida
muestraHGeom &lt;- 15

probabilidadHGeom &lt;- dhyper(exitosHGeom, exitosEnPoblacion, fallasHGeom, muestraHGeom)

#Calcular en el experimento anterior, la probabilidad de que sea rechazado

probabilidadHGeomAcumulada &lt;- phyper(exitosEnPoblacion, exitosEnPoblacion, fallasHGeom, muestraHGeom) - probabilidadHGeom</code></pre>
<hr />
</div>
<div id="poisson" class="section level2">
<h2><span class="header-section-number">3.7</span> Poisson</h2>
<pre class="r"><code>#x: cantidad de exitos
xEjA &lt;- 0
xEjC &lt;- 10

lambda &lt;- 4

#Resolucion
ejAPois &lt;- dpois(xEjA, lambda*2)
ejCPois &lt;- dpois(xEjC, lambda*3)

#ppois(q, lambda, lower.tail = TRUE, log.p = FALSE)
ejBPois &lt;- ppois(1, lambda, lower.tail = FALSE)</code></pre>
<hr />
</div>
</div>
<div id="distribuciones-continuas" class="section level1">
<h1><span class="header-section-number">4</span> Distribuciones continuas</h1>
<div id="normal" class="section level2">
<h2><span class="header-section-number">4.1</span> Normal</h2>
<p>Ejercicio 2 - Guía 5</p>
<p>En una planta industrial el consumo mensual de combustible es una variable aleatoria distribuida normalmente con media 20000 litros y desvío estándar 2500 litros.</p>
<ol style="list-style-type: lower-alpha">
<li>¿Qué porcentaje de los meses se consume menos de 24000 litros?</li>
</ol>
<pre class="r"><code>visualize.norm(stat = c(24000), mu = 20000, sd = 2500, section =&quot;lower&quot;)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/norm-1.png" width="432" /></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Ídem con más de 18000 lts.</li>
</ol>
<pre class="r"><code>visualize.norm(stat = c(18000), mu = 20000, sd = 2500, section =&quot;upper&quot;)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-22-1.png" width="432" /></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Ídem entre 18000 y 24000 lts.</li>
</ol>
<pre class="r"><code>visualize.norm(stat = c(18000,24000), mu = 20000, sd = 2500, section = &quot;bounded&quot;)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-23-1.png" width="432" /></p>
<p>Función de distribución normal estandarizada:</p>
<pre class="r"><code>f &lt;- function(x) {
  1/(sqrt(2 * pi)) * exp(-0.5 * x^2)
}

x=seq(-5,5,by = 0.01)
plot(x,f(x), type=&quot;l&quot;, col=&quot;red&quot;)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/norm2-1.png" width="432" /></p>
<p>Vamos a probar con tres valores reales nuestra función de distribución:</p>
<pre class="r"><code>valores &lt;- c(-1.96, 0, 1.96)

f(valores)</code></pre>
<pre><code>## [1] 0.05844094 0.39894228 0.05844094</code></pre>
<pre class="r"><code># vamos a comparar estos valores con los valores calculados por dnorm():
f(valores) == dnorm(valores)</code></pre>
<pre><code>## [1] TRUE TRUE TRUE</code></pre>
<p>Vamos a hallar la probabilidad del 1er valor integrando la función de distribución:</p>
<pre class="r"><code># op1:
integrate(f, 
          lower = -Inf, 
          upper = -1.96)</code></pre>
<pre><code>## 0.0249979 with absolute error &lt; 1.9e-05</code></pre>
<pre class="r"><code># op2:
pnorm(-1.96)</code></pre>
<pre><code>## [1] 0.0249979</code></pre>
<hr />
<p>Otro ejemplo:</p>
<p>Dada la siguiente función definida para x&gt;=0:</p>
<pre class="r"><code>f &lt;- function(x) {
  1/(sqrt(2 * pi)) * exp(-0.5 * x^2)
}</code></pre>
<ol style="list-style-type: decimal">
<li>Indicar si dicha función cumple las propiedades correspondientes a una función de densidad de probabilidad.</li>
<li>Hallar la esperanza de dicha de dicha función de probabilidad.</li>
<li>Considere que X es una VA con la función de densidad indicada en el enunciado: Calcule la esperanza de <span class="math inline">\(X^2\)</span>.</li>
<li>Calcule la varianza de X.</li>
</ol>
<p>Nota: Resuelto al final del hands-on</p>
<hr />
<p>Ejemplo con la distribución Gamma:</p>
<p>Primero vamos a definir la función de densidad de la distribución Gamma:</p>
<pre class="r"><code>fgamma&lt;-function(x,a,s) {1/(s^a*gamma(a))*x^(a-1)*exp(-x/s)}</code></pre>
<p>Gráfica de la distribución Gamma variando algunos de sus parámetros:</p>
<pre class="r"><code>x=seq(0,20,by = 0.001)
plot(x,fgamma(x,1,2), xlim = c(0,20), ylim = c(0,0.5), col=&quot;red&quot;, type=&quot;l&quot;, ylab=&quot;&quot;)
lines(x,fgamma(x,2,2), xlim = c(0,20),  col=&quot;green&quot;)
lines(x,fgamma(x,3,2), xlim = c(0,20), col=&quot;blue&quot;)
lines(x,fgamma(x,5,1), xlim = c(0,20), col=&quot;magenta&quot;)
lines(x,fgamma(x,9,0.5))</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-28-1.png" width="432" /></p>
<p>Ahora supondremos una VA que sigue una distribución Gamma con a=9 y l=0.5, vamos a hallar P(X=5):</p>
<pre class="r"><code>integrate(fgamma,0,5,9,0.5)</code></pre>
<pre><code>## 0.6671803 with absolute error &lt; 6.3e-09</code></pre>
<p>Confirmamos el valor utilizando la función de r:</p>
<pre class="r"><code>pgamma(5,9,2)</code></pre>
<pre><code>## [1] 0.6671803</code></pre>
<p>Tarea: 1) Hallar la esperenza y la varianza de dicha VA. 2) Mostrar con una simulación que la media de dicha VA tiende a &quot;a*1/s&quot; es decir 18.</p>
<hr />
<p>Mostrar con una simulación que el porcentaje de datos entre 1 SD es aproximadamente 68%. O sea que el 68 % de los datos de una distribución normal están dentro de [μ-σ;μ+σ].</p>
<p>Nota: Resuelto al final del hands-on</p>
<div id="teorema-central-del-límite" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Teorema central del límite</h3>
<p>Vamos a tomar una muestra aleatoria en una población normal cuda media (de la muestra) es μ=170 y desviación típica σ=12. No conocemos el tamaño de la población. Fijamos inicialmente un tamaño de muestra n=25, tomamos la muestra y calculamos su media:</p>
<pre class="r"><code>n=25
muestra1=rnorm(n,170,12)
media1=mean(muestra1)
media1</code></pre>
<pre><code>## [1] 168.8082</code></pre>
<p>En esta muestra hemos obtenido un valor medio muestral de 172.2. Si repetimos el proceso obtenemos otra media distinta:</p>
<pre class="r"><code>muestra2=rnorm(n,170,12)
media2=mean(muestra2)
media2</code></pre>
<pre><code>## [1] 166.6675</code></pre>
<p>Y si volvemos a repetir:</p>
<pre class="r"><code>muestra3=rnorm(n,170,12)
media3=mean(muestra3)
media3</code></pre>
<pre><code>## [1] 168.5224</code></pre>
<p>En este punto el lector habrá observado que cada vez que se toma una muestra se obtiene una media diferente. Como a priori es imposible predecir en cada muestreo cuál será el valor medio resultante, la media muestral es una variable aleatoria. El lector habrá observado también que las medias muestrales se parecen a la media de la población, μ=170. Cabe preguntarse entonces: ¿tenderá la media muestral a comportarse de esta manera en todas las muestras? ¿Cuánto llega a apartarse de la media de la población?</p>
<p>Para responder a estas preguntas podemos repetir el proceso anterior no tres, sino muchísimas más veces. En R esto es muy sencillo de hacer. Una forma muy eficiente de replicar muchas veces el proceso anterior consiste en encapsular el proceso de muestreo en una función que haremos depender del tamaño de la muestra:</p>
<pre class="r"><code>mediaMuestral=function(n){
  muestra=rnorm(n,170,12)
  media=mean(muestra)
  return(media)
}</code></pre>
<p>Cada vez que ejecutemos esta función estaremos eligiendo una muestra de tamaño n de esa población N(170,12) y calculando su media:</p>
<pre class="r"><code>mediaMuestral(25)</code></pre>
<pre><code>## [1] 174.2577</code></pre>
<pre class="r"><code>mediaMuestral(25)</code></pre>
<pre><code>## [1] 167.3962</code></pre>
<pre class="r"><code>mediaMuestral(25)</code></pre>
<pre><code>## [1] 173.7282</code></pre>
<p>Para repetir m veces el proceso de extraer una muestra de tamaño n y calcular su media podemos utilizar la función replicate():</p>
<pre class="r"><code>m=10000
muchasMedias=replicate(m,mediaMuestral(25))</code></pre>
<p>La media y desviación típica de todas estas medias muestrales son:</p>
<pre class="r"><code>mean(muchasMedias)</code></pre>
<pre><code>## [1] 170.0018</code></pre>
<pre class="r"><code>sd(muchasMedias)</code></pre>
<pre><code>## [1] 2.415415</code></pre>
<p>Por último, representamos gráficamente la distribución de frecuencias de estas medias muestrales mediante un histograma, al que le superponemos una densidad normal:</p>
<pre class="r"><code>hist(muchasMedias,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(160,180),freq=FALSE,ylim=c(0,0.75),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 25&quot;)
curve(dnorm(x,170,sd(muchasMedias)),xlim=c(160,180),col=&quot;blue&quot;,lwd=2,add=TRUE)      </code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-38-1.png" width="432" /></p>
<p>A estas alturas, para el lector debe de haber quedado claro que la media muestral es una variable aleatoria, y que su distribución de probabilidad es muy parecida a la normal; además la media de todas las medias muestrales es casi idéntica a la media de la población.</p>
<p>¿Cuál es el efecto de aumentar el tamaño de la muestra? Podemos evaluarlo repitiendo el proceso anterior para n=50, n=100 y n=500 (en todos los casos presentaremos los gráficos en la misma escala para facilitar la comparación):</p>
<pre class="r"><code>muchasMedias50=replicate(m,mediaMuestral(50))
muchasMedias100=replicate(m,mediaMuestral(100))
muchasMedias500=replicate(m,mediaMuestral(500))
mean(muchasMedias50); sd(muchasMedias50)</code></pre>
<pre><code>## [1] 170.0362</code></pre>
<pre><code>## [1] 1.692841</code></pre>
<pre class="r"><code>mean(muchasMedias100); sd(muchasMedias100)</code></pre>
<pre><code>## [1] 169.9984</code></pre>
<pre><code>## [1] 1.20171</code></pre>
<pre class="r"><code>mean(muchasMedias500); sd(muchasMedias500)</code></pre>
<pre><code>## [1] 170.0096</code></pre>
<pre><code>## [1] 0.5346144</code></pre>
<pre class="r"><code>hist(muchasMedias50,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(160,180),freq=FALSE,ylim=c(0,0.75),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 50&quot;)
curve(dnorm(x,170,sd(muchasMedias50)),xlim=c(160,180),col=&quot;blue&quot;,lwd=2,add=TRUE)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-39-1.png" width="432" /></p>
<pre class="r"><code>hist(muchasMedias100,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(160,180),freq=FALSE,ylim=c(0,0.75),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 100&quot;)
curve(dnorm(x,170,sd(muchasMedias100)),xlim=c(160,180),col=&quot;blue&quot;,lwd=2,add=TRUE)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-39-2.png" width="432" /></p>
<pre class="r"><code>hist(muchasMedias500,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(160,180),freq=FALSE,ylim=c(0,0.75),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 500&quot;)
curve(dnorm(x,170,sd(muchasMedias500)),xlim=c(160,180),col=&quot;blue&quot;,lwd=2,add=TRUE,n=200)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-39-3.png" width="432" /></p>
<p>Resulta evidente en las gráficas, que el incremento del tamaño de la muestra tiene como consecuencia que las posibles medias muestrales se concentran más en torno a su media; en otras palabras, cuanto más grande sea la muestra, más probable es que la media de la muestra esté muy cerca de la media de la población. Puede comprobarse además que la desviación típica de las medias muestrales es en todos los casos un valor muy parecido a σ/√n=12/√n:</p>
<table>
<thead>
<tr class="header">
<th>Tamaño de muestra (n)</th>
<th>Desviación típica de las medias muestrales</th>
<th>σ/√n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>25</td>
<td>2.40882</td>
<td>2.4</td>
</tr>
<tr class="even">
<td>50</td>
<td>1.69587</td>
<td>1.69706</td>
</tr>
<tr class="odd">
<td>100</td>
<td>1.18425</td>
<td>1.2</td>
</tr>
<tr class="even">
<td>1000</td>
<td>0.53569</td>
<td>0.53666</td>
</tr>
</tbody>
</table>
<p>Tras esta serie de simulaciones, el lector debe haber quedado bastante convencido de que la media muestral de variables N(μ,σ) es una variable aleatoria también normal de media μ y desviación típica σ/√n.</p>
<p>Ejercicio:</p>
<p>Hemos visto la media de variables normales es también normal. ¿Ocurrirá lo mismo si las variables que se promedian no son normales? Podemos aquí plantear el siguiente ejercicio, para que el lector “descubra” el teorema central del límite.</p>
<ol style="list-style-type: decimal">
<li>Repetir el proceso anterior cuando la variable aleatoria original es de Poisson de parámetro λ=1.3</li>
<li>Idem cuando es exponencial de parámetro μ=1.5</li>
<li>Idem cuando es uniforme en el intervalo [5,10]</li>
</ol>
<p>Nota: Resuelto al final del hands-on.</p>
<hr />
</div>
<div id="otro-ejemplo" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Otro ejemplo</h3>
<p>Vamos a definir 2 poblaciones: pobA y pobB. Ambas tienen 10.000 habitantes. La pobA sigue una distribución uniforme [0,1], mientras que la pobB sigue una distribución exponencial con alfa=10. Vamos a tomar muestras de 10 personas en ambas poblaciones y vamos a mostras que, en ambos casos, el histograma de las medias (muestrales) siguen una distribución normal:</p>
<pre class="r"><code># generamos los 10000 elementos de pobA:
runi&lt;-runif(100000,0,1)

# extraemos 10 elementos al azar de la población. Y esta extracción la repetimos 1000 veces. 
means&lt;-NULL
for(i in 1:1000){
  # calculo la media de los 10 elementos extraídos al azar de la pobA:
  means&lt;-c(means,mean(sample(runi,size = 10)))
}

# generamos los 10000 elementos de pobB:
rexpon&lt;-rexp(100000,10)

# extraemos 10 elementos al azar de la población. Y esta extracción la repetimos 1000 veces. 
means2&lt;-NULL
for(i in 1:1000){
  # calculo la media de los 10 elementos extraídos al azar de la pobB:
  means2&lt;-c(means2,mean(sample(rexpon,size = 10)))
}

# visualizo las 2 distribuciones poblacionales y las 2 distribuciones de las medias muestrales: 
par(mfrow=c(2,2))
hist(runi, main = &quot;Distribución uniforme&quot;)
plot(density(means), col=&#39;blue&#39;, xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;&quot;, axes=F, add=T)
par(new=T)
hist(means, main=&quot;Distribución de las medias muestrales&quot;)
hist(rexpon, main=&quot;Distribución exponencial&quot;)
plot(density(means2), col=&#39;blue&#39;, axes=F, xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;&quot;, add=T)
par(new=T)
hist(means2, main=&quot;Distribución de las medias muestrales&quot;)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/tcl1-1.png" width="432" /></p>
<p>Ahora vamos a mostrar que la aproximación de las medias muestras de un experimento se asemeja a una distribución normal también cuando la distribución poblacional es binomial.</p>
<p>Vamos a simular 10000 habitantes de una población que sigue una B(10,0.4):</p>
<pre class="r"><code>mysample&lt;-NULL
for(m in 1:10000){
  mysample&lt;-c(mysample,rbinom(1,size=10,prob=0.4))
}
mupob&lt;-mean(mysample)
sdpob&lt;-sd(mysample)</code></pre>
<p>Vamos a repetir 20000 veces el experimento: vamos a tomar 10 elementos de la población, le vamos a sacar la media a esa muestra (de 10 els) y vamos a graficar la distribución de esas 20000 medias.</p>
<pre class="r"><code>summeans&lt;-NULL
for(k in 1:20000) {
  mysubsample&lt;-sample(mysample,10)
  summeans&lt;-c(summeans, mean(mysubsample))
}

par(mfrow=c(1,1))
plot(density(summeans), col=&#39;blue&#39;, axes=F, xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;&quot;, add=T)</code></pre>
<pre><code>## Warning in plot.window(...): &quot;add&quot; is not a graphical parameter</code></pre>
<pre><code>## Warning in plot.xy(xy, type, ...): &quot;add&quot; is not a graphical parameter</code></pre>
<pre><code>## Warning in title(...): &quot;add&quot; is not a graphical parameter</code></pre>
<pre class="r"><code>par(new=T)
hist(summeans, main = &quot;Aproximación de la Binomial&quot;)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-40-1.png" width="432" /></p>
<hr />
</div>
</div>
</div>
<div id="resumen-de-las-intrucciones-de-distribución-en-r" class="section level1">
<h1><span class="header-section-number">5</span> Resumen de las intrucciones de distribución en R</h1>
<p>El paquete <code>stats</code> de R (que se instala por defecto al instalar R, y se carga en memoria siempre que iniciamos sesión) implementa numerosas funciones para la realización de cálculos asociados a distintas distribuciones de probabilidad. Entre las utilizadas más comunmente podemos citar:</p>
<table>
<thead>
<tr class="header">
<th>Distribuciones Discretas</th>
<th></th>
<th>Distribuciones Continuas</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Distribución</td>
<td>Nombre en R</td>
<td></td>
<td>Distribución</td>
<td>Nombre en R</td>
</tr>
<tr class="even">
<td>——————-</td>
<td>————-</td>
<td>—</td>
<td>—————</td>
<td>————-</td>
</tr>
<tr class="odd">
<td>Binomial</td>
<td>binom</td>
<td></td>
<td>Uniforme</td>
<td>unif</td>
</tr>
<tr class="even">
<td>Poisson</td>
<td>pois</td>
<td></td>
<td>Normal</td>
<td>norm</td>
</tr>
<tr class="odd">
<td>Geométrica</td>
<td>geom</td>
<td></td>
<td>t Student</td>
<td>t</td>
</tr>
<tr class="even">
<td>Hipergeométrica</td>
<td>hyper</td>
<td></td>
<td>F Fisher</td>
<td>F</td>
</tr>
<tr class="odd">
<td>Binomial Negativa</td>
<td>nbinom</td>
<td></td>
<td>Chi-Cuadrado</td>
<td>chisq</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td>Exponencial</td>
<td>exp</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td>Gamma</td>
<td>gamma</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td>Weibull</td>
<td>weibull</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td>W de Wilcoxon</td>
<td>wilcox</td>
</tr>
</tbody>
</table>
</div>
<div id="resueltos" class="section level1">
<h1><span class="header-section-number">6</span> Resueltos</h1>
<div id="μ-σμσ" class="section level2">
<h2><span class="header-section-number">6.1</span> [μ-σ;μ+σ]</h2>
<p>Mostrar con una simulación que el porcentaje de datos entre 1 SD es aproximadamente 68%. O sea que el 68 % de los datos de una distribución normal están dentro de [μ-σ;μ+σ].</p>
<pre class="r"><code>#valores generados
propg &lt;- rnorm(10000)
#estadísticos
n = length(propg)
mean = mean(propg)
sd = sd(propg)
#función para calcular proporción
proporcion &lt;- function(nSD){
  lo = mean - nSD*sd
  hi = mean + nSD*sd
  percent = sum(propg&gt;=lo 
                &amp; propg&lt;=hi)/n *100
}
#cálculo de la proporción (en %) para 1 y 2 desviaciones estándares:
print(paste(&quot;Porcentaje de datos entre 1 SD es &quot;,proporcion(1),&quot;%&quot;, sep=&quot;&quot;))</code></pre>
<pre><code>## [1] &quot;Porcentaje de datos entre 1 SD es 68.21%&quot;</code></pre>
<hr />
</div>
<div id="función-de-densidad-esperanza-y-varianza" class="section level2">
<h2><span class="header-section-number">6.2</span> función de densidad, esperanza y varianza</h2>
<p>Dada la siguiente función definida para x&gt;=0:</p>
<pre class="r"><code>f &lt;- function(x) {
  1/(sqrt(2 * pi)) * exp(-0.5 * x^2)
}</code></pre>
<ol style="list-style-type: decimal">
<li>Indicar si dicha función cumple las propiedades correspondientes a una función de densidad de probabilidad.</li>
</ol>
<p>Respuesta: tenemos que chequear que f(x)&gt;0 y que la integral de f(x)=1.</p>
<ul>
<li>f(x)&gt;0 por la definición de la fórmula</li>
<li>para demostrar la segunda propiedad, vamos a integrar y ver si da 1:</li>
</ul>
<pre class="r"><code>f &lt;- function(x){x/4*exp(-x^2/8)}</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Hallar la esperanza de dicha función de probabilidad.</li>
</ol>
<pre class="r"><code>ex &lt;- function(x){x*f(x)}
expected_value &lt;- integrate(ex, 0, Inf)$value
expected_value</code></pre>
<pre><code>## [1] 2.506628</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Considere que X es una VA con la función de densidad indicada en el enunciado: Calcule la esperanza de <span class="math inline">\(X^2\)</span>.</li>
</ol>
<pre class="r"><code>ex2 &lt;- function(x){x^2*f(x)}
integrate(ex2, 0, Inf)$value</code></pre>
<pre><code>## [1] 8</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Calcule la varianza de X.</li>
</ol>
<pre class="r"><code>variance &lt;- integrate(ex2, 0, Inf)$value - expected_value^2</code></pre>
<hr />
</div>
<div id="bolillero-de-15-bolillas" class="section level2">
<h2><span class="header-section-number">6.3</span> Bolillero de 15 bolillas</h2>
<p>Un bolillero para un examen tiene 15 bolillas.</p>
<ol style="list-style-type: decimal">
<li>Suponga que el examen consiste en explicar 3 bolillas estraídas del bolillero. Simule la generación de los tres temas que le tocaría a un alumno al azar.</li>
</ol>
<pre class="r"><code>sample(1:15, 3) # se supone que son extracciones sin resposición. </code></pre>
<pre><code>## [1] 4 9 2</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Muestre, a través de una simulación, que la probabilidad de que un alumno saque un tema es la misma para todos los temas.</li>
</ol>
<pre><code>## [1] 6649</code></pre>
<pre><code>## [1] 6838</code></pre>
<pre><code>## [1] 6581</code></pre>
<pre><code>## [1] 6664</code></pre>
<hr />
</div>
<div id="varias-distribuciones-para-el-tcl" class="section level2">
<h2><span class="header-section-number">6.4</span> Varias distribuciones para el TCL</h2>
<p>Ejercicio:</p>
<p>Hemos visto la media de variables normales es también normal. ¿Ocurrirá lo mismo si las variables que se promedian no son normales? Podemos aquí plantear el siguiente ejercicio, para que el lector “descubra” el teorema central del límite.</p>
<ol style="list-style-type: decimal">
<li>Repetir el proceso anterior cuando la variable aleatoria original es de Poisson de parámetro λ=1.3 Fijamos inicialmente un tamaño de muestra n=25, tomamos la muestra y calculamos su media:</li>
</ol>
<pre class="r"><code>n=25
muestraPois=rpois(n,lambda = 1.3)
mediaPois=mean(muestraPois)
mediaPois</code></pre>
<pre><code>## [1] 1.88</code></pre>
<p>Obtuvimos como resultado <code>mediaPois</code>. Podemos repetir el experimento muchas veces y obtendremos valores distintos.</p>
<p>Una forma muy eficiente de replicar muchas veces el proceso anterior consiste en encapsular el proceso de muestreo en una función que haremos depender del tamaño de la muestra:</p>
<pre class="r"><code>mediaMuestralPois=function(n){
  muestra=rpois(n,lambda = 1.3)
  media=mean(muestra)
  return(media)
}</code></pre>
<p>Cada vez que ejecutemos esta función estaremos eligiendo una muestra de tamaño n de esa población Poiss(1.3) y calculando su media:</p>
<pre class="r"><code>mediaMuestralPois(25)</code></pre>
<pre><code>## [1] 1.64</code></pre>
<pre class="r"><code>mediaMuestralPois(25)</code></pre>
<pre><code>## [1] 1.32</code></pre>
<pre class="r"><code>mediaMuestralPois(25)</code></pre>
<pre><code>## [1] 1.48</code></pre>
<p>Para repetir m veces el proceso de extraer una muestra de tamaño n y calcular su media podemos utilizar la función replicate():</p>
<pre class="r"><code>m=10000
muchasMediasPois=replicate(m,mediaMuestralPois(25))</code></pre>
<p>La media y desviación típica de todas estas medias muestrales son:</p>
<pre class="r"><code>mean(muchasMediasPois)</code></pre>
<pre><code>## [1] 1.298132</code></pre>
<pre class="r"><code>sd(muchasMediasPois)</code></pre>
<pre><code>## [1] 0.2291595</code></pre>
<p>Por último, representamos gráficamente la distribución de frecuencias de estas medias muestrales mediante un histograma, al que le superponemos una densidad normal:</p>
<pre class="r"><code>hist(muchasMediasPois,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(0.5,2),freq=FALSE,ylim=c(0,2.5),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 25&quot;)
curve(dnorm(x,1.3,sd(muchasMediasPois)),xlim=c(0.5,2),col=&quot;blue&quot;,lwd=2,add=TRUE)    </code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-53-1.png" width="432" /></p>
<p>Repetimos el proceso anterior para n=50, n=100 y n=500 (en todos los casos presentaremos los gráficos en la misma escala para facilitar la comparación):</p>
<pre class="r"><code>muchasMedias50=replicate(m,mediaMuestralPois(50))
muchasMedias100=replicate(m,mediaMuestralPois(100))
muchasMedias500=replicate(m,mediaMuestralPois(500))
mean(muchasMedias50); sd(muchasMedias50)</code></pre>
<pre><code>## [1] 1.301442</code></pre>
<pre><code>## [1] 0.1586518</code></pre>
<pre class="r"><code>mean(muchasMedias100); sd(muchasMedias100)</code></pre>
<pre><code>## [1] 1.300779</code></pre>
<pre><code>## [1] 0.1143771</code></pre>
<pre class="r"><code>mean(muchasMedias500); sd(muchasMedias500)</code></pre>
<pre><code>## [1] 1.3003</code></pre>
<pre><code>## [1] 0.05174032</code></pre>
<pre class="r"><code>hist(muchasMedias50,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(0.5,2),freq=FALSE,ylim=c(0,9),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 50&quot;)
curve(dnorm(x,1.3,sd(muchasMedias50)),xlim=c(0.5,2),col=&quot;blue&quot;,lwd=2,add=TRUE)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-54-1.png" width="432" /></p>
<pre class="r"><code>hist(muchasMedias100,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(0.5,2),freq=FALSE,ylim=c(0,9),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 100&quot;)
curve(dnorm(x,1.3,sd(muchasMedias100)),xlim=c(0.5,2),col=&quot;blue&quot;,lwd=2,add=TRUE)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-54-2.png" width="432" /></p>
<pre class="r"><code>hist(muchasMedias500,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(0.5,2),freq=FALSE,ylim=c(0,9),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 500&quot;)
curve(dnorm(x,1.3,sd(muchasMedias500)),xlim=c(0.5,2),col=&quot;blue&quot;,lwd=2,add=TRUE,n=200)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-54-3.png" width="432" /></p>
<ol start="2" style="list-style-type: decimal">
<li>Idem cuando es exponencial de parámetro μ=1.5</li>
</ol>
<p>Fijamos inicialmente un tamaño de muestra n=25, tomamos la muestra y calculamos su media:</p>
<pre class="r"><code>n=25
muestraExp=rexp(n, rate = 1.5)
mediaExp=mean(muestraExp)
mediaExp</code></pre>
<pre><code>## [1] 0.9931689</code></pre>
<p>Obtuvimos como resultado <code>mediaExp</code>. Notar que la esperanza de la exponencial es 1/μ. Podemos repetir el experimento muchas veces y obtendremos valores distintos.</p>
<p>Una forma muy eficiente de replicar muchas veces el proceso anterior consiste en encapsular el proceso de muestreo en una función que haremos depender del tamaño de la muestra:</p>
<pre class="r"><code>mediaMuestralExp=function(n){
  muestra=rexp(n,rate = 1.5)
  media=mean(muestra)
  return(media)
}</code></pre>
<p>Cada vez que ejecutemos esta función estaremos eligiendo una muestra de tamaño n de esa población E(1.5) y calculando su media:</p>
<pre class="r"><code>mediaMuestralExp(25)</code></pre>
<pre><code>## [1] 0.7297273</code></pre>
<pre class="r"><code>mediaMuestralExp(25)</code></pre>
<pre><code>## [1] 0.6811721</code></pre>
<pre class="r"><code>mediaMuestralExp(25)</code></pre>
<pre><code>## [1] 0.6072632</code></pre>
<p>Para repetir m veces el proceso de extraer una muestra de tamaño n y calcular su media podemos utilizar la función replicate():</p>
<pre class="r"><code>m=10000
muchasMediasExp=replicate(m,mediaMuestralExp(25))</code></pre>
<p>La media y desviación típica de todas estas medias muestrales son:</p>
<pre class="r"><code>mean(muchasMediasExp)</code></pre>
<pre><code>## [1] 0.6674992</code></pre>
<pre class="r"><code>sd(muchasMediasExp)</code></pre>
<pre><code>## [1] 0.1319331</code></pre>
<p>Por último, representamos gráficamente la distribución de frecuencias de estas medias muestrales mediante un histograma, al que le superponemos una densidad normal:</p>
<pre class="r"><code>hist(muchasMediasExp,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(0.2,1.2),freq=FALSE,ylim=c(0,4),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 25&quot;)
curve(dnorm(x,1/1.5,sd(muchasMediasExp)),xlim=c(0.2,1.2),col=&quot;blue&quot;,lwd=2,add=TRUE)    </code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-60-1.png" width="432" /></p>
<p>Repetimos el proceso anterior para n=50, n=100 y n=500 (en todos los casos presentaremos los gráficos en la misma escala para facilitar la comparación):</p>
<pre class="r"><code>muchasMedias50=replicate(m,mediaMuestralExp(50))
muchasMedias100=replicate(m,mediaMuestralExp(100))
muchasMedias500=replicate(m,mediaMuestralExp(500))
mean(muchasMedias50); sd(muchasMedias50)</code></pre>
<pre><code>## [1] 0.6674026</code></pre>
<pre><code>## [1] 0.09457704</code></pre>
<pre class="r"><code>mean(muchasMedias100); sd(muchasMedias100)</code></pre>
<pre><code>## [1] 0.6671971</code></pre>
<pre><code>## [1] 0.06582275</code></pre>
<pre class="r"><code>mean(muchasMedias500); sd(muchasMedias500)</code></pre>
<pre><code>## [1] 0.6672379</code></pre>
<pre><code>## [1] 0.02964205</code></pre>
<pre class="r"><code>hist(muchasMedias50,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(0.2,1.2),freq=FALSE,ylim=c(0,15),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 25&quot;)
curve(dnorm(x,1/1.5,sd(muchasMedias50)),xlim=c(0.2,1.2),col=&quot;blue&quot;,lwd=2,add=TRUE)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-61-1.png" width="432" /></p>
<pre class="r"><code>hist(muchasMedias100,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(0.2,1.2),freq=FALSE,ylim=c(0,15),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 25&quot;)
curve(dnorm(x,1/1.5,sd(muchasMedias100)),xlim=c(0.2,1.2),col=&quot;blue&quot;,lwd=2,add=TRUE)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-61-2.png" width="432" /></p>
<pre class="r"><code>hist(muchasMedias500,xlab=&quot;Media muestral&quot;, ylab=&quot;Frecuencia&quot;, col=&quot;lightcyan&quot;,
     xlim=c(0.2,1.2),freq=FALSE,ylim=c(0,15),
     main=&quot;Histograma de las medias muestrales observadas\n en 10000 muestras de tamaño 25&quot;)
curve(dnorm(x,1/1.5,sd(muchasMedias500)),xlim=c(0.2,1.2),col=&quot;blue&quot;,lwd=2,add=TRUE)</code></pre>
<p><img src="basic_statistics_in_R_files/figure-html/unnamed-chunk-61-3.png" width="432" /></p>
<ol start="3" style="list-style-type: decimal">
<li>Idem cuando es uniforme en el intervalo [5,10]</li>
</ol>
<p>El procedimiento es idéntico a los anteior pero la generación aleatoria de los números de población se debe hacer con la función correspondiente.</p>
<hr />
</div>
</div>
<div id="material-para-consulta" class="section level1">
<h1><span class="header-section-number">7</span> Material para consulta</h1>
<ul>
<li><p>G. Jay Kerns (Youngstown State University, Ohio) ha creado dos paquetes de R, prob, IPSUR que corresponden a dos libros de probabilidad y estadística de este autor (los libros pueden descargarse libremente <a href="http://prob.r-forge.r-project.org/doc/prob.pdf">aquí</a> y <a href="http://cran.r-project.org/web/packages/IPSUR/vignettes/IPSUR.pdf">aquí</a>), y los paquetes se pueden descargar directamente de CRAN. Ambos libros se pueden utilizar para un curso de probabilidad y estadística de primero de carrera. Los paquetes citados, además de incluir versiones pdf de ambos libros, incluyen datos, funciones y ejemplos de utilización de R para el aprendizaje del cálculo de probabilidades y la estadística.</p></li>
<li><p><a href="http://www.ats.ucla.edu/stat/r/modules/prob_dist.htm" class="uri">http://www.ats.ucla.edu/stat/r/modules/prob_dist.htm</a></p></li>
<li><p><a href="http://www.r-tutor.com/elementary-statistics/probability-distributions" class="uri">http://www.r-tutor.com/elementary-statistics/probability-distributions</a></p></li>
<li><p><a href="https://rpubs.com/dsfernandez/418180" class="uri">https://rpubs.com/dsfernandez/418180</a></p></li>
<li><p><a href="https://www.econometrics-with-r.org/1-introduction.html">Excelente material de Estadística en R</a></p></li>
<li><p><a href="https://rstudio-pubs-static.s3.amazonaws.com/13301_6641d73cfac741a59c0a851feb99e98b.html">Diagramas de Venn</a></p></li>
</ul>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
